<?xml version="1.0" encoding="UTF-8"?>
<services version="1.0" xmlns:deploy="vespa">

    <container id="default" version="1.0">
        <component id="openai" class="ai.vespa.llm.clients.OpenAI">
            <config name="ai.vespa.llm.clients.llm-client">
                <!-- <apiKeySecretName>...</apiKeySecretName> -->
            </config>
        </component>
        <component id="embedder" type="hugging-face-embedder">
            <transformer-model path="model/model.onnx"/>
            <tokenizer-model path="model/tokenizer.json"/>
        </component>
        <document-processing>
            <chain id="default">
                <documentprocessor id="ai.vespa.cloud.docsearch.OutLinksDocumentProcessor" bundle="vespacloud-docsearch"/>
            </chain>
        </document-processing>
        <search>
            <chain id="default" inherits="vespa">
                <searcher id="ai.vespa.cloud.docsearch.DocumentationSearcher" bundle="vespacloud-docsearch"/>
            </chain>
            <chain id="suggest" inherits="vespa">
                <searcher id="ai.vespa.cloud.docsearch.SuggestionSearcher" bundle="vespacloud-docsearch"/>
            </chain>
            <chain id="llmsearch" inherits="vespa">
                <searcher id="ai.vespa.cloud.docsearch.LLMSearcher" bundle="vespacloud-docsearch"/>
            </chain>

            <chain id="slackmessage" inherits="vespa">
                <searcher id="ai.vespa.cloud.docsearch.SlackMessageSearcher" bundle="vespacloud-docsearch"/>
            </chain>
            <chain id="thread" inherits="vespa">
                <searcher id="ai.vespa.cloud.docsearch.ThreadSearcher" bundle="vespacloud-docsearch"/>
            </chain>

            <chain id="combinedllmsearch" inherits="vespa">
                <federation id="combination">
                    <source idref="thread"/>
                    <source idref="llmsearch" /> 
                </federation>
            </chain>


            <chain id="ragsearch" inherits="vespa">
                <searcher id="ai.vespa.search.llm.RAGSearcher">
                    <config name="ai.vespa.search.llm.llm-searcher">
                        <providerId>openai</providerId>
                        <promptTemplate>files/prompt.txt</promptTemplate>
                    </config>
                </searcher>
                <searcher id="ai.vespa.cloud.docsearch.LLMSearcher" bundle="vespacloud-docsearch"/>
            </chain>
            <chain id="combinedragsearch" inherits="vespa">
                <searcher id="ai.vespa.search.llm.RAGSearcher">
                    <config name="ai.vespa.search.llm.llm-searcher">
                        <providerId>openai</providerId>
                        <promptTemplate>files/prompt_combined.txt</promptTemplate>
                    </config>
                </searcher>
                <federation id="combinedragsearchsource">
                    <source idref="thread"/>
                    <source idref="llmsearch" /> 
                </federation>
            </chain>
        </search>
        <document-api/>
        <nodes count="2" exclusive="true">
            <resources vcpu="2" memory="8Gb" disk="32Gb" />
            <resources vcpu="4" memory="16Gb" disk="125Gb" deploy:instance="default" deploy:environment="prod" deploy:region="aws-us-east-1c">
                <gpu count="1" memory="16Gb"/>
            </resources>
            <resources vcpu="2" memory="8Gb" disk="32Gb" architecture="x86_64" deploy:instance="enclave" />
        </nodes>
    </container>

    <container id="playground" version="1.0">
        <handler id="ai.vespa.cloud.playground.TensorPlaygroundHandler" bundle="vespacloud-docsearch">
            <binding>http://*/playground/*</binding>
        </handler>
        <nodes count="2">
            <resources vcpu="2" memory="8Gb" disk="32Gb" />
            <resources vcpu="2" memory="8Gb" disk="32Gb" architecture="x86_64" deploy:instance="enclave" />
        </nodes>
    </container>
    
    <content id="documentation" version="1.0">
        <config name="vespa.config.search.summary.juniperrc">
            <length>1024</length> <!-- default 256 -->
            <min_length>512</min_length> <!-- default 128 -->
            <surround_max>512</surround_max> <!-- default 128 -->
            <max_matches>2</max_matches> <!-- default 3 -->
            <winsize>512</winsize> <!-- default 200 -->
        </config>
        <min-redundancy>2</min-redundancy>
        <documents>
            <document mode="index" type="doc"/>
            <document mode="index" type="paragraph"/>
            <document mode="index" type="term"/>
            <document mode="index" type="purchase"/>
            <document mode="index" type="slack_message"/>
        </documents>
        <nodes count="2">
            <resources vcpu="2" memory="8Gb" disk="32Gb" architecture="x86_64" deploy:instance="enclave" />
        </nodes>
        <nodes count="50" deploy:instance="enclave" deploy:environment="prod" deploy:region="aws-eu-west-1a">
            <resources vcpu="1" memory="8Gb" disk="32Gb" />
        </nodes>
    </content>

</services>
